import streamlit as st
import json
import pandas as pd
import plotly.express as px
from datetime import datetime

import boto3
from opensearchpy import OpenSearch, RequestsHttpConnection
from requests_aws4auth import AWS4Auth

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'expander_state' not in st.session_state:
    st.session_state.expander_state = False  # ê¸°ë³¸ê°’ì„ Trueë¡œ ì„¤ì •
    
    
# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì„œë²„ ì¸í”„ë¼ ê²€ìƒ‰ ì„œë¹„ìŠ¤",
    layout="wide",
    initial_sidebar_state="expanded"
)

# AWS Bedrock í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
@st.cache_resource
def get_bedrock_client():
    return boto3.client(
        service_name='bedrock-runtime',
        region_name='us-west-2'
    )

# AWS ì¸ì¦ ì„¤ì •
region = 'us-west-2'  # ì˜ˆ: 'us-west-2'
service = 'aoss'
credentials = boto3.Session().get_credentials()
awsauth = AWS4Auth(credentials.access_key, credentials.secret_key,
                   region, service, session_token=credentials.token)

# OpenSearch Serverless ì—°ê²° ì„¤ì •
host = 'o0hj5d4vh1k6bxab969l.us-west-2.aoss.amazonaws.com'
port = 443

# OpenSearch í´ë¼ì´ì–¸íŠ¸ ìƒì„±
opensearch_client = OpenSearch(
    hosts=[{'host': host, 'port': port}],
    http_auth=awsauth,
    use_ssl=True,
    verify_certs=True,
    connection_class=RequestsHttpConnection
)

# Titan ì„ë² ë”© ìƒì„±
def get_titan_embedding(text, bedrock_client, normalize=True):
    response = bedrock_client.invoke_model(
        modelId='amazon.titan-embed-text-v2:0',
        contentType='application/json',
        accept='application/json',
        body=json.dumps({
            "inputText": text,
            "dimensions": 1024,
            "normalize": normalize
        })
    )
    return json.loads(response['body'].read())['embedding']

# ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” Index ê°€ì ¸ì˜¤ê¸°
def get_opensearch_indices(client):
    indices = client.cat.indices(format="json")
    return [index['index'] for index in indices if not index['index'].startswith('.')]

# ì•± ì œëª©
st.title("ğŸ” ì„œë²„ ì¸í”„ë¼ ê²€ìƒ‰ ì‹œìŠ¤í…œ")
st.markdown("""
ì´ ì‹œìŠ¤í…œì€ Amazon Titan Embeddings V2ì™€ OpenSearchë¥¼ í™œìš©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ê³¼ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ì„ ê²°í•©í•˜ì—¬ ë” ì •í™•í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
""")

# ì‚¬ì´ë“œë°” í•„í„°
st.sidebar.header("ê²€ìƒ‰ì˜µì…˜")
indices = get_opensearch_indices(opensearch_client)

selected_index = st.sidebar.selectbox(
    "ì‚¬ìš©í•  Indexë¥¼ ì„ íƒí•˜ì„¸ìš”.",
    options=indices,
    index=2  # ê¸°ë³¸ê°’ìœ¼ë¡œ ì²« ë²ˆì§¸ ì¸ë±ìŠ¤ ì„ íƒ
)

# í•„í„° ì„¤ì •
with st.sidebar.expander("ìƒì„¸ í•„í„°", expanded=True):
    os_filter = st.multiselect(
        "ìš´ì˜ì²´ì œ",
        ["Ubuntu 22.04", "CentOS 7", "Windows Server 2019", "Red Hat 8", "Amazon Linux 2"]
    )
    
    status_filter = st.multiselect(
        "ì„œë²„ ìƒíƒœ",
        ["running", "stopped", "maintenance", "terminated"]
    )
    
    cpu_range = st.slider(
        "CPU ì½”ì–´ ìˆ˜",
        min_value=1,
        max_value=64,
        value=(1, 64)
    )
    
    memory_range = st.slider(
        "ë©”ëª¨ë¦¬ (GB)",
        min_value=2,
        max_value=256,
        value=(2, 256)
    )

    applyfilter = st.checkbox(
        label = "í•„í„° ì ìš©",
        value=False
    )
    
    
# ê²€ìƒ‰ ê°€ì¤‘ì¹˜ ì„¤ì •
with st.sidebar.expander("ê²€ìƒ‰ ê°€ì¤‘ì¹˜ ì„¤ì •", expanded=True):
    keyword_weight = st.slider(
        "í‚¤ì›Œë“œ ê²€ìƒ‰ ê°€ì¤‘ì¹˜",
        min_value=0.0,
        max_value=1.0,
        value=0.3,
        step=0.1
    )
    vector_weight = 1 - keyword_weight
    
    

# ë©”ì¸ ê²€ìƒ‰ ì¸í„°í˜ì´ìŠ¤
search_query = st.text_input("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: database server, ì›¹ì„œë²„")

if search_query:
    try:
        bedrock_client = get_bedrock_client()
        # opensearch_client = get_opensearch_client()
        
        # ì¿¼ë¦¬ ë²¡í„° ìƒì„±
        query_vector = get_titan_embedding(search_query, bedrock_client)
        
        # ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
        search_body = {
            "size": 10,
            "track_scores": True,
            "query": {
                "bool": {
                    "should": [
                        # í…ìŠ¤íŠ¸ ê²€ìƒ‰
                        {
                            "match": {
                                "full_text": {
                                    "query": search_query,
                                    "boost": keyword_weight  # í…ìŠ¤íŠ¸ ê²€ìƒ‰ ê°€ì¤‘ì¹˜
                                }
                            }
                        },
                        # ë²¡í„° ê²€ìƒ‰
                        {
                            "knn": {
                                "vector_embedding": {
                                    "vector": query_vector,  # Titan Embeddingsë¡œ ìƒì„±í•œ ë²¡í„°
                                    "k": 10,
                                    "boost": vector_weight
                                }
                            }
                        }
                    ]
                    # "minimum_should_match": 1
                    # í•„í„° ì¡°ê±´ ì¶”ê°€
                }
            }
        }
        
        # í•„í„° ì ìš©
        if applyfilter:
            if os_filter:
                search_body["query"]["bool"]["filter"].append({"terms": {"os": os_filter}})
            if status_filter:
                search_body["query"]["bool"]["filter"].append({"terms": {"server_status": status_filter}})
            
            if cpu_range:
                if "filter" not in search_body["query"]["bool"]:
                    search_body["query"]["bool"]["filter"] = []
                search_body["query"]["bool"]["filter"].append({
                    "range": {"cpu": {"gte": cpu_range[0], "lte": cpu_range[1]}}
                })

            if memory_range:
                if "filter" not in search_body["query"]["bool"]:
                    search_body["query"]["bool"]["filter"] = []
                search_body["query"]["bool"]["filter"].append({
                    "range": {"memory": {"gte": memory_range[0], "lte": memory_range[1]}}
                })
        
        # ê²€ìƒ‰ ì‹¤í–‰
        results = opensearch_client.search(
            index=selected_index,
            body=search_body
        )
        
        st.write(search_body)
        
        # ê²°ê³¼ ì²˜ë¦¬
        hits = results['hits']['hits']
        st.subheader(f"ê²€ìƒ‰ ê²°ê³¼: {len(hits)}ê°œ ë°œê²¬")
        
        # ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        if hits:
            df = pd.DataFrame([hit['_source'] for hit in hits])
            
            # í†µê³„ ëŒ€ì‹œë³´ë“œ
            col1, col2 = st.columns(2)
            
            with col1:
                # OS ë¶„í¬ ì°¨íŠ¸
                os_counts = df['os'].value_counts()
                fig1 = px.pie(values=os_counts.values, names=os_counts.index, title='ìš´ì˜ì²´ì œ ë¶„í¬')
                st.plotly_chart(fig1)
            
            with col2:
                # ì„œë²„ ìƒíƒœ ë¶„í¬
                status_counts = df['server_status'].value_counts()
                fig2 = px.bar(x=status_counts.index, y=status_counts.values, title='ì„œë²„ ìƒíƒœ ë¶„í¬')
                st.plotly_chart(fig2)
            
            # ìƒì„¸ ê²°ê³¼ í‘œì‹œ
            for hit in hits:
                with st.expander(f"ğŸ–¥ï¸ {hit['_source']['instance_name']} (ìŠ¤ì½”ì–´: {hit['_score']:.2f})"):
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("**ğŸ“‹ ê¸°ë³¸ ì •ë³´**")
                        st.write(f"ğŸ”¹ OS: {hit['_source']['os']}")
                        st.write(f"ğŸ”¹ ìƒíƒœ: {hit['_source']['server_status']}")
                        st.write(f"ğŸ”¹ ìœ„ì¹˜: {hit['_source']['location']}")
                        st.write(f"ğŸ”¹ ë¶€ì„œ: {hit['_source']['department']}")
                    
                    with col2:
                        st.markdown("**ğŸ’» ë¦¬ì†ŒìŠ¤ ì •ë³´**")
                        st.write(f"ğŸ”¹ CPU: {hit['_source']['cpu']} cores")
                        st.write(f"ğŸ”¹ ë©”ëª¨ë¦¬: {hit['_source']['memory']} GB")
                        st.write(f"ğŸ”¹ ë””ìŠ¤í¬: {hit['_source']['disk']} GB")
                        st.write(f"ğŸ”¹ IP: {hit['_source']['ip_address']}")
                    
                    st.markdown("**ğŸ¯ ìš©ë„**")
                    st.write(hit['_source']['purpose'])
                    
                    st.markdown("**ğŸ“… ë‚ ì§œ ì •ë³´**")
                    st.write(f"ë“±ë¡ì¼: {hit['_source']['registration_date']}")
                    st.write(f"ìµœì¢… ìˆ˜ì •ì¼: {hit['_source']['last_updated']}")
                    
                    st.markdown("---")
                    st.write(hit['_source']['full_text'])
        else:
            st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        st.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

# ì‚¬ìš© ê°€ì´ë“œ
with st.sidebar.expander("ğŸ’¡ ì‚¬ìš© ê°€ì´ë“œ"):
    st.markdown("""
    1. **ê²€ìƒ‰ì–´ ì…ë ¥**
        - ìì—°ì–´ë¡œ ê²€ìƒ‰ ê°€ëŠ¥
        - êµ¬ì²´ì ì¸ í‚¤ì›Œë“œ ì‚¬ìš© ê°€ëŠ¥
    
    2. **í•„í„° ì‚¬ìš©**
        - OS ì„ íƒ
        - ì„œë²„ ìƒíƒœ ì„ íƒ
        - CPU/ë©”ëª¨ë¦¬ ë²”ìœ„ ì§€ì •
    
    3. **ê²€ìƒ‰ ê°€ì¤‘ì¹˜ ì¡°ì •**
        - í‚¤ì›Œë“œ ê²€ìƒ‰ê³¼ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ì˜ ë¹„ì¤‘ ì¡°ì ˆ ê°€ëŠ¥
    
    4. **ê²°ê³¼ í™•ì¸**
        - í†µê³„ ì°¨íŠ¸ë¡œ ì „ì²´ í˜„í™© íŒŒì•…
        - ìƒì„¸ ì •ë³´ëŠ” í™•ì¥ íŒ¨ë„ì—ì„œ í™•ì¸
    """)
